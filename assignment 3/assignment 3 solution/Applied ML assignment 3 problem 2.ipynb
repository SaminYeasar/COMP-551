{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#loc = 'D:/University materials/Winter 2018/Applied ML/winter 2018/Assignments/assignment 3/hwk3_datasets/yelp-train.txt'\n",
    "loc = 'yelp-train.txt'\n",
    "yelp_train = pd.read_table(loc,header=None,names=['review','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = yelp_train.label.unique()\n",
    "labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "frq_vect = [] # frequency vector; counts the number of time lables got repeated\n",
    "for itr in range ( 0,len(labels) ):\n",
    "    frq_vect = np.append (frq_vect, (sum(yelp_train.label==labels[itr])) ) \n",
    "    \n",
    "No_examples = len(yelp_train.label)\n",
    "class_prob = frq_vect/No_examples # probability of perticular class occurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Classifier computing F1 score for Yelp train,test,valid data prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomPred (labels,No_examples,class_prob,true_labels):\n",
    "    # prediticng class with random classifier and getting F1 score\n",
    "    pred_labels = np.random.choice(labels, No_examples, p=class_prob)\n",
    "    from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "    yelp_f1 = f1_score(true_labels,pred_labels,average='micro')\n",
    "    yelp_acc = accuracy_score(true_labels,pred_labels)\n",
    "\n",
    "    print('F1 score',yelp_f1)\n",
    "    print('Accuracy',yelp_acc)\n",
    "    return (yelp_f1,yelp_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score for Yelp training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.2671428571428571\n",
      "Accuracy 0.2671428571428571\n"
     ]
    }
   ],
   "source": [
    "No_examples = len(yelp_train.label)\n",
    "true_labels = np.asarray(yelp_train.label)\n",
    "f1_train,train_acc = getRandomPred (labels,No_examples,class_prob,true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score for Yelp validaion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.273\n",
      "Accuracy 0.273\n"
     ]
    }
   ],
   "source": [
    "#loc = 'D:/University materials/Winter 2018/Applied ML/winter 2018/Assignments/assignment 3/hwk3_datasets/yelp-valid.txt'\n",
    "loc = 'yelp-valid.txt'\n",
    "yelp_valid = pd.read_table(loc,header=None,names=['review','label'])\n",
    "# for Yelp training data\n",
    "true_labels = np.asarray(yelp_valid.label)\n",
    "No_examples = len(yelp_valid.label)\n",
    "f1_valid,valid_acc = getRandomPred (labels,No_examples,class_prob,true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score for Yelp testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.2775\n",
      "Accuracy 0.2775\n"
     ]
    }
   ],
   "source": [
    "#loc = 'D:/University materials/Winter 2018/Applied ML/winter 2018/Assignments/assignment 3/hwk3_datasets/yelp-test.txt'\n",
    "loc = 'yelp-test.txt'\n",
    "yelp_test = pd.read_table(loc,header=None,names=['review','label'])\n",
    "# for Yelp training data\n",
    "true_labels = np.asarray(yelp_test.label)\n",
    "No_examples = len(yelp_test.label)\n",
    "f1_test,test_acc = getRandomPred (labels,No_examples,class_prob,true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Majority Classifier computing F1 score for Yelp train,test,valid data prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frq_class = labels[np.argmax(frq_vect)]\n",
    "frq_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMajorityPred(true_labels,No_examples):\n",
    "    pred_labels = np.repeat(frq_class,len(true_labels))\n",
    "    from sklearn.metrics import f1_score,accuracy_score\n",
    "    yelp_f1 = f1_score(true_labels,pred_labels,average='micro')\n",
    "    yelp_acc = accuracy_score(true_labels,pred_labels)\n",
    "\n",
    "    print('F1 score',yelp_f1)\n",
    "    print('Accuracy',yelp_acc)\n",
    "    return yelp_f1,yelp_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### F1 score for Yelp training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.3525714285714286\n",
      "Accuracy 0.3525714285714286\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.asarray(yelp_train.label)\n",
    "No_examples = len(yelp_train.label) \n",
    "f1_train,train_acc = getMajorityPred(true_labels,No_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### F1 score for Yelp testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.351\n",
      "Accuracy 0.351\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.asarray(yelp_test.label)\n",
    "No_examples = len(yelp_test.label) \n",
    "f1_test,test_acc = getMajorityPred(true_labels,No_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### F1 score for Yelp validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.356\n",
      "Accuracy 0.356\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.asarray(yelp_valid.label)\n",
    "No_examples = len(yelp_valid.label) \n",
    "f1_valid,valid_acc = getMajorityPred(true_labels,No_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying naive bayes, Decision tree and Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextPreprocess(text):   \n",
    "    text = text.str.lower()\n",
    "    text = text.str.replace('[^\\w\\s]','')    \n",
    "    text = text.str.replace('[0-9]','')\n",
    "    text = text.str.replace('_','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_csv('yelp-vocab.txt',header=None,names = ['word','id','frequency'])\n",
    "#vocabtotext = vocab.word.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc = 'D:/University materials/Winter 2018/Applied ML/winter 2018/Assignments/assignment 3/hwk3_datasets/yelp-train.txt'\n",
    "loc = 'yelp-train.txt'\n",
    "yelp_train = pd.read_table(loc,header=None,names=['review','label'])\n",
    "yelp_train.review = TextPreprocess(yelp_train.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'yelp-test.txt'\n",
    "yelp_test = pd.read_table(loc,header=None,names=['review','label'])\n",
    "yelp_test.review = TextPreprocess(yelp_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'valid-train.txt'\n",
    "yelp_valid = pd.read_table(loc,header=None,names=['review','label'])\n",
    "yelp_valid.review = TextPreprocess(yelp_valid.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_counts(doc): \n",
    "    #myDictionary = collections.OrderedDict()\n",
    "    import collections\n",
    "    myDictionary = {}  \n",
    "    myFile = doc\n",
    "    field = myFile.split()\n",
    "    frequency=collections.Counter(field) #for bag of frequency\n",
    "    \n",
    "    #for line in range(len(field)):\n",
    "        #myDictionary[line] = [field[line] , line]\n",
    "        #myDictionary[field[line]] =  line\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sparse_matrix(texts, vocab):\n",
    "    \n",
    "    from scipy.sparse import csr_matrix\n",
    "    \"\"\" Generate a sparse matrix from the given texts, using doc_counts function \"\"\"\n",
    "    D = len(texts)\n",
    "    V = len(vocab.word)\n",
    "        \n",
    "    mat_bag_data = []\n",
    "    mat_freq_data = []\n",
    "    mat_indptr = [0]\n",
    "    mat_indices = []\n",
    "\n",
    "    for i,doc in enumerate(texts):\n",
    "      #  counts,frequency = doc_counts(doc) # counts basically nested list contains words\n",
    "                                            # frequency hold the number repeatations\n",
    "        frequency = doc_counts(doc) \n",
    "        \n",
    "        #N = len(counts)  # idk why N requires \n",
    "        used = 0\n",
    "        for word,count in frequency.items():\n",
    "            if vocab.loc[vocab.word== word].empty:\n",
    "                # if the word is missing in vocab we skip it\n",
    "                continue                        \n",
    "            else:\n",
    "                index = vocab[vocab.word == word].iloc[0].id - 1  \n",
    "                # -1 cause our id starts from 1 but in matrix first indice is 0, so we get 10001 example matrix as we skipped 0\n",
    "                # so -1 so that\n",
    "                #print(word)\n",
    "                mat_indices.append(index)\n",
    "                mat_bag_data.append(1)\n",
    "                mat_freq_data.append(frequency[word])\n",
    "                used += 1\n",
    "        mat_indptr.append(mat_indptr[-1] + used)\n",
    "        \n",
    "    mat_bag = csr_matrix((mat_bag_data, mat_indices, mat_indptr), (D,V+1), dtype='int')\n",
    "    mat_freq = csr_matrix((mat_freq_data, mat_indices, mat_indptr), (D,V+1), dtype='int') \n",
    "    # mat_freq has not normalized, normalize it while using it in classifier \n",
    "    #mat[:,0] = 1\n",
    "    \n",
    "        \n",
    "    return mat_bag,mat_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################\n",
    "'''\n",
    "One sprase matrix constructed save it and call the data when its needed as computation is time consuming\n",
    "'''\n",
    "\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computing sparse matrix of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26min 39s\n"
     ]
    }
   ],
   "source": [
    "%lsmagic\n",
    "%time mat_bag,mat_freq = generate_sparse_matrix(yelp_train.review, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "scipy.sparse.save_npz('yelp_train_bag_mat.npz', mat_bag)\n",
    "scipy.sparse.save_npz('yelp_train_freq_mat.npz', mat_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computing sparse matrix of testing data\n",
    "### computing sparse matrix of validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 20s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%lsmagic\n",
    "%time test_mat_bag,test_mat_freq = generate_sparse_matrix(yelp_test.review, vocab)\n",
    "%time valid_mat_bag,valid_mat_freq = generate_sparse_matrix(yelp_valid.review, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('yelp_test_bag_mat.npz', test_mat_bag)\n",
    "scipy.sparse.save_npz('yelp_test_freq_mat.npz', test_mat_freq)\n",
    "\n",
    "scipy.sparse.save_npz('yelp_valid_bag_mat.npz', valid_mat_bag)\n",
    "scipy.sparse.save_npz('yelp_valid_freq_mat.npz', valid_mat_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis if Classification Efficiency using bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "train_mat = scipy.sparse.load_npz('yelp_train_bag_mat.npz')\n",
    "test_mat = scipy.sparse.load_npz('yelp_test_bag_mat.npz')\n",
    "valid_mat = scipy.sparse.load_npz('yelp_valid_bag_mat.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = yelp_train.iloc[np.random.choice(len(yelp_train.review),20)]       # randomly picking dataset to train\n",
    "#validation_set = yelp_valid.iloc[np.random.choice(len(yelp_valid.review),20)]      # randomly picking dataset to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_true = yelp_train.label\n",
    "valid_y_true = yelp_valid.label\n",
    "test_y_true = yelp_test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computeing accuracy and F1 score for predicting \"training data\"\n",
    "# input sparse matrix data that needs to be predicted\n",
    "def getClassifierEff (Data,true_y,clf):\n",
    "    from sklearn.metrics import f1_score,accuracy_score\n",
    "    y_pred = clf.predict(Data)\n",
    "    acc = accuracy_score(true_y,y_pred)\n",
    "    f1 = f1_score(true_y,y_pred,average='micro')\n",
    "    return f1,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training classifier with \"training data\"\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\machine learning\\python 3.5.2\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "Hyp = [0, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "yelp_valid_f1 = []\n",
    "yelp_valid_acc = []\n",
    "for itr in range(len(Hyp)):\n",
    "    naive_clf = BernoulliNB(alpha=Hyp[itr]).fit(train_mat, train_y_true)\n",
    "    f1 , acc = getClassifierEff (valid_mat,valid_y_true,naive_clf)\n",
    "    yelp_valid_f1.append(f1)\n",
    "    yelp_valid_acc.append(acc)\n",
    "   # print('yelp_valid_f1',yelp_valid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38,\n",
       " 0.38,\n",
       " 0.382,\n",
       " 0.386,\n",
       " 0.387,\n",
       " 0.394,\n",
       " 0.401,\n",
       " 0.408,\n",
       " 0.42299999999999993,\n",
       " 0.427,\n",
       " 0.402]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_valid_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for hyper parameter alpha = 0.01 we get max F1 score\n"
     ]
    }
   ],
   "source": [
    "optim_alpha = Hyp[np.argmax(yelp_valid_f1)]\n",
    "print('for hyper parameter alpha =',Hyp[np.argmax(yelp_valid_f1)],'we get max F1 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_train_f1 0.749\n",
      "yelp_test_f1 0.435\n"
     ]
    }
   ],
   "source": [
    "naive_clf = BernoulliNB( alpha=optim_alpha ).fit(train_mat, train_y_true)\n",
    "\n",
    "train_f1 , train_acc = getClassifierEff (train_mat,train_y_true,naive_clf)\n",
    "test_f1 , test_acc = getClassifierEff (test_mat,test_y_true,naive_clf)\n",
    "\n",
    "print('yelp_train_f1',train_f1)\n",
    "print('yelp_test_f1',test_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.tree.DecisionTreeClassifier(criterion=’gini’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = ['gini','entropy'] #criterion \n",
    "split = ['best','random'] #splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_valid_f1 0.352 when we use criterion gini and splitter best\n",
      "yelp_valid_f1 0.347 when we use criterion gini and splitter random\n",
      "yelp_valid_f1 0.37 when we use criterion entropy and splitter best\n",
      "yelp_valid_f1 0.361 when we use criterion entropy and splitter random\n"
     ]
    }
   ],
   "source": [
    "yelp_valid_f1 = []\n",
    "yelp_valid_acc = []\n",
    "for itr1 in range(len(crit)):\n",
    "    for itr2 in range(len(split)):\n",
    "        tree_clf = tree.DecisionTreeClassifier(criterion = crit[itr1], splitter = split[itr2]).fit(train_mat, train_y_true)\n",
    "        f1,acc = getClassifierEff (valid_mat,valid_y_true,tree_clf)\n",
    "        yelp_valid_f1.append(f1)\n",
    "        yelp_valid_acc.append(acc)\n",
    "        \n",
    "        print('yelp_valid_f1',f1,'when we use criterion',crit[itr1],'and splitter',split[itr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_train_f1 1.0\n",
      "yelp_test_f1 0.333\n"
     ]
    }
   ],
   "source": [
    "tree_clf = tree.DecisionTreeClassifier(criterion = 'entropy', splitter = 'best').fit(train_mat, train_y_true)\n",
    "yelp_train_f1,yelp_train_acc = getClassifierEff (train_mat,train_y_true,tree_clf)\n",
    "yelp_test_f1,yelp_test_acc = getClassifierEff (test_mat,test_y_true,tree_clf)\n",
    "\n",
    "print('yelp_train_f1',yelp_train_f1)\n",
    "print('yelp_test_f1',yelp_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.svm.LinearSVC(penalty=’l2’, loss=’squared_hinge’, dual=True, tol=0.0001, C=1.0, multi_class=’ovr’, fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_clf = LinearSVC().fit(train_mat, train_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = ['l1','l2']\n",
    "los = ['squared_hinge'] # gives error for hinge\n",
    "dul = [False] # gives error for dual = true. \n",
    "tolerance = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "C_param = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_valid_f1 0.443 when we use penalty l1\n",
      "yelp_valid_f1 0.44 when we use penalty l2\n"
     ]
    }
   ],
   "source": [
    "yelp_valid_f1 = []\n",
    "yelp_valid_acc = []\n",
    "for itr1 in range(len(pen)):\n",
    "\n",
    "    linear_clf = LinearSVC(penalty=pen[itr1] , dual=False).fit(train_mat, train_y_true)\n",
    "    f1 , acc = getClassifierEff (valid_mat,valid_y_true,linear_clf)\n",
    "    yelp_valid_f1.append(f1)\n",
    "    yelp_valid_acc.append(acc)\n",
    "            \n",
    "    print('yelp_valid_f1',f1,'when we use penalty',pen[itr1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-10 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-10 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-10 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-10 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-10 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-10 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 1e-10 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 1e-10 C 0.001\n",
      "yelp_valid_f1 0.425 when we use penalty l1 tolerence 1e-10 C 0.01\n",
      "yelp_valid_f1 0.496 when we use penalty l1 tolerence 1e-10 C 0.1\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-09 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-09 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-09 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-09 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-09 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-09 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 1e-09 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 1e-09 C 0.001\n",
      "yelp_valid_f1 0.425 when we use penalty l1 tolerence 1e-09 C 0.01\n",
      "yelp_valid_f1 0.496 when we use penalty l1 tolerence 1e-09 C 0.1\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-08 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-08 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-08 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-08 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-08 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-08 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 1e-08 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 1e-08 C 0.001\n",
      "yelp_valid_f1 0.425 when we use penalty l1 tolerence 1e-08 C 0.01\n",
      "yelp_valid_f1 0.496 when we use penalty l1 tolerence 1e-08 C 0.1\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-07 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-07 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-07 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-07 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-07 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-07 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 1e-07 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 1e-07 C 0.001\n",
      "yelp_valid_f1 0.425 when we use penalty l1 tolerence 1e-07 C 0.01\n",
      "yelp_valid_f1 0.496 when we use penalty l1 tolerence 1e-07 C 0.1\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-06 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-06 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-06 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-06 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-06 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-06 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 1e-06 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 1e-06 C 0.001\n",
      "yelp_valid_f1 0.425 when we use penalty l1 tolerence 1e-06 C 0.01\n",
      "yelp_valid_f1 0.496 when we use penalty l1 tolerence 1e-06 C 0.1\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-05 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-05 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-05 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-05 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-05 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 1e-05 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 1e-05 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 1e-05 C 0.001\n",
      "yelp_valid_f1 0.425 when we use penalty l1 tolerence 1e-05 C 0.01\n",
      "yelp_valid_f1 0.496 when we use penalty l1 tolerence 1e-05 C 0.1\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.0001 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.0001 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.0001 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.0001 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.0001 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.0001 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 0.0001 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 0.0001 C 0.001\n",
      "yelp_valid_f1 0.425 when we use penalty l1 tolerence 0.0001 C 0.01\n",
      "yelp_valid_f1 0.496 when we use penalty l1 tolerence 0.0001 C 0.1\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.001 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.001 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.001 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.001 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.001 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.001 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 0.001 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 0.001 C 0.001\n",
      "yelp_valid_f1 0.425 when we use penalty l1 tolerence 0.001 C 0.01\n",
      "yelp_valid_f1 0.496 when we use penalty l1 tolerence 0.001 C 0.1\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.01 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.01 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.01 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.01 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.01 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.01 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 0.01 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 0.01 C 0.001\n",
      "yelp_valid_f1 0.425 when we use penalty l1 tolerence 0.01 C 0.01\n",
      "yelp_valid_f1 0.493 when we use penalty l1 tolerence 0.01 C 0.1\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.1 C 1e-10\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.1 C 1e-09\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.1 C 1e-08\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.1 C 1e-07\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.1 C 1e-06\n",
      "yelp_valid_f1 0.084 when we use penalty l1 tolerence 0.1 C 1e-05\n",
      "yelp_valid_f1 0.356 when we use penalty l1 tolerence 0.1 C 0.0001\n",
      "yelp_valid_f1 0.372 when we use penalty l1 tolerence 0.1 C 0.001\n",
      "yelp_valid_f1 0.42299999999999993 when we use penalty l1 tolerence 0.1 C 0.01\n",
      "yelp_valid_f1 0.5 when we use penalty l1 tolerence 0.1 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-10 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-10 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-10 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-10 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-10 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-09 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-09 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-09 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-09 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-09 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-08 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-08 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-08 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-08 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-08 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-07 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-07 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-07 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-07 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-07 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-06 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-06 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-06 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-06 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-06 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-05 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-05 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-05 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-05 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-05 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 0.0001 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 0.0001 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 0.0001 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 0.0001 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 0.0001 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 0.001 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 0.001 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 0.001 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 0.001 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 0.001 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-06\n",
      "yelp_valid_f1 0.38 when we use penalty l2 tolerence 0.01 C 1e-05\n",
      "yelp_valid_f1 0.429 when we use penalty l2 tolerence 0.01 C 0.0001\n",
      "yelp_valid_f1 0.494 when we use penalty l2 tolerence 0.01 C 0.001\n",
      "yelp_valid_f1 0.5 when we use penalty l2 tolerence 0.01 C 0.01\n",
      "yelp_valid_f1 0.474 when we use penalty l2 tolerence 0.01 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-06\n",
      "yelp_valid_f1 0.38 when we use penalty l2 tolerence 0.1 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 0.1 C 0.0001\n",
      "yelp_valid_f1 0.494 when we use penalty l2 tolerence 0.1 C 0.001\n",
      "yelp_valid_f1 0.508 when we use penalty l2 tolerence 0.1 C 0.01\n",
      "yelp_valid_f1 0.47500000000000003 when we use penalty l2 tolerence 0.1 C 0.1\n"
     ]
    }
   ],
   "source": [
    "yelp_valid_f1 = []\n",
    "yelp_valid_acc = []\n",
    "for itr1 in range(len(pen)):\n",
    "    for itr2 in range(len(tolerance)):\n",
    "        for itr3 in range(len(C_param)):\n",
    "            linear_clf = LinearSVC(penalty=pen[itr1],tol=tolerance[itr2],C=C_param[itr3],dual=False).fit(train_mat, train_y_true)\n",
    "            f1 , acc = getClassifierEff (valid_mat,valid_y_true,linear_clf)\n",
    "            yelp_valid_f1.append(f1)\n",
    "            yelp_valid_acc.append(acc)\n",
    "            \n",
    "            print('yelp_valid_f1',f1,'when we use penalty',pen[itr1],'tolerence',tolerance[itr2],'C',C_param[itr3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_train_f1 0.8092857142857144\n",
      "yelp_test_f1 0.502\n",
      "yelp_valid_f1 0.508\n"
     ]
    }
   ],
   "source": [
    "linear_clf = LinearSVC(penalty='l2',tol=0.1,C=0.01,dual=False).fit(train_mat, train_y_true)\n",
    "yelp_train_f1,yelp_train_acc = getClassifierEff (train_mat,train_y_true,linear_clf)\n",
    "yelp_test_f1,yelp_test_acc = getClassifierEff (test_mat,test_y_true,linear_clf)\n",
    "yelp_valid_f1,yelp_valid_acc = getClassifierEff (valid_mat,valid_y_true,linear_clf)\n",
    "print('yelp_train_f1',yelp_train_f1)\n",
    "print('yelp_test_f1',yelp_test_f1)\n",
    "print('yelp_valid_f1',yelp_valid_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for combination of penalty='l2' , loss='hinge',dual=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = ['l2']\n",
    "los = ['hinge'] # gives error for hinge\n",
    "dul = [True] # gives error for dual = true. \n",
    "tolerance = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "C_param = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-10 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-10 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-10 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-10 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-10 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-10 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-09 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-09 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-09 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-09 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-09 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-09 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-08 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-08 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-08 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-08 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-08 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-08 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-07 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-07 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-07 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-07 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-07 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-07 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-06 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-06 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-06 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-06 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-06 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-06 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 1e-05 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 1e-05 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 1e-05 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 1e-05 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 1e-05 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 1e-05 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.0001 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 0.0001 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 0.0001 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 0.0001 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 0.0001 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 0.0001 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.001 C 1e-06\n",
      "yelp_valid_f1 0.37899999999999995 when we use penalty l2 tolerence 0.001 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 0.001 C 0.0001\n",
      "yelp_valid_f1 0.495 when we use penalty l2 tolerence 0.001 C 0.001\n",
      "yelp_valid_f1 0.502 when we use penalty l2 tolerence 0.001 C 0.01\n",
      "yelp_valid_f1 0.473 when we use penalty l2 tolerence 0.001 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.01 C 1e-06\n",
      "yelp_valid_f1 0.38 when we use penalty l2 tolerence 0.01 C 1e-05\n",
      "yelp_valid_f1 0.429 when we use penalty l2 tolerence 0.01 C 0.0001\n",
      "yelp_valid_f1 0.494 when we use penalty l2 tolerence 0.01 C 0.001\n",
      "yelp_valid_f1 0.5 when we use penalty l2 tolerence 0.01 C 0.01\n",
      "yelp_valid_f1 0.474 when we use penalty l2 tolerence 0.01 C 0.1\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-10\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-09\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-08\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-07\n",
      "yelp_valid_f1 0.35500000000000004 when we use penalty l2 tolerence 0.1 C 1e-06\n",
      "yelp_valid_f1 0.38 when we use penalty l2 tolerence 0.1 C 1e-05\n",
      "yelp_valid_f1 0.433 when we use penalty l2 tolerence 0.1 C 0.0001\n",
      "yelp_valid_f1 0.494 when we use penalty l2 tolerence 0.1 C 0.001\n",
      "yelp_valid_f1 0.508 when we use penalty l2 tolerence 0.1 C 0.01\n",
      "yelp_valid_f1 0.47500000000000003 when we use penalty l2 tolerence 0.1 C 0.1\n"
     ]
    }
   ],
   "source": [
    "yelp_valid_f1 = []\n",
    "yelp_valid_acc = []\n",
    "for itr1 in range(len(pen)):\n",
    "    for itr2 in range(len(tolerance)):\n",
    "        for itr3 in range(len(C_param)):\n",
    "            linear_clf = LinearSVC(penalty=pen[itr1],tol=tolerance[itr2],C=C_param[itr3],dual=False).fit(train_mat, train_y_true)\n",
    "            f1 , acc = getClassifierEff (valid_mat,valid_y_true,linear_clf)\n",
    "            yelp_valid_f1.append(f1)\n",
    "            yelp_valid_acc.append(acc)\n",
    "            \n",
    "            print('yelp_valid_f1',f1,'when we use penalty',pen[itr1],'tolerence',tolerance[itr2],'C',C_param[itr3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_train_f1 0.7461428571428571\n",
      "yelp_test_f1 0.506\n"
     ]
    }
   ],
   "source": [
    "linear_clf = LinearSVC(penalty='l2',tol=0.1,C=0.01,loss='hinge',dual=True).fit(train_mat, train_y_true)\n",
    "yelp_train_f1,yelp_train_acc = getClassifierEff (train_mat,train_y_true,linear_clf)\n",
    "yelp_test_f1,yelp_test_acc = getClassifierEff (test_mat,test_y_true,linear_clf)\n",
    "print('yelp_train_f1',yelp_train_f1)\n",
    "print('yelp_test_f1',yelp_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
