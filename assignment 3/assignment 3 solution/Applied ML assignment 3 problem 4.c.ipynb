{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Classification Efficiency of IMDB data using frquency bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextPreprocess(text):   \n",
    "    text = text.str.lower()\n",
    "    text = text.str.replace('[^\\w\\s]','')    \n",
    "    text = text.str.replace('[0-9]','')\n",
    "    text = text.str.replace('_','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_csv('IMDB-vocab.txt',header=None,names = ['word','id','frequency'])\n",
    "#vocabtotext = vocab.word.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc = 'D:/University materials/Winter 2018/Applied ML/winter 2018/Assignments/assignment 3/hwk3_datasets/IMDB-train.txt'\n",
    "loc = 'IMDB-train.txt'\n",
    "IMDB_train = pd.read_table(loc,header=None,names=['review','label'])\n",
    "IMDB_train.review = TextPreprocess(IMDB_train.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc = 'D:/University materials/Winter 2018/Applied ML/winter 2018/Assignments/assignment 3/hwk3_datasets/IMDB-test.txt'\n",
    "loc = 'IMDB-test.txt'\n",
    "IMDB_test = pd.read_table(loc,header=None,names=['review','label'])\n",
    "IMDB_test.review = TextPreprocess(IMDB_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc = 'D:/University materials/Winter 2018/Applied ML/winter 2018/Assignments/assignment 3/hwk3_datasets/IMDB-valid.txt'\n",
    "loc = 'IMDB-valid.txt'\n",
    "IMDB_valid = pd.read_table(loc,header=None,names=['review','label'])\n",
    "IMDB_valid.review = TextPreprocess(IMDB_valid.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOne sprase matrix constructed save it and call the data when its needed as computation is time consuming\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################################################################################\n",
    "'''\n",
    "One sprase matrix constructed save it and call the data when its needed as computation is time consuming\n",
    "'''\n",
    "\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "train_mat = scipy.sparse.load_npz('IMDB_train_freq_mat.npz')\n",
    "test_mat = scipy.sparse.load_npz('IMDB_test_freq_mat.npz')\n",
    "valid_mat = scipy.sparse.load_npz('IMDB_valid_freq_mat.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = yelp_train.iloc[np.random.choice(len(yelp_train.review),20)]       # randomly picking dataset to train\n",
    "#validation_set = yelp_valid.iloc[np.random.choice(len(yelp_valid.review),20)]      # randomly picking dataset to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_true = IMDB_train.label\n",
    "valid_y_true = IMDB_valid.label\n",
    "test_y_true = IMDB_test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computeing accuracy and F1 score for predicting \"training data\"\n",
    "# input sparse matrix data that needs to be predicted\n",
    "def getClassifierEff (Data,true_y,clf):\n",
    "    from sklearn.metrics import f1_score,accuracy_score\n",
    "    y_pred = clf.predict(Data)\n",
    "    acc = accuracy_score(true_y,y_pred)\n",
    "    f1 = f1_score(true_y,y_pred,average='micro')\n",
    "    return f1,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training classifier with \"training data\"\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\machine learning\\python 3.5.2\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "Hyp = [0, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "IMDB_valid_f1 = []\n",
    "IMDB_valid_acc = []\n",
    "for itr in range(len(Hyp)):\n",
    "    naive_clf = MultinomialNB(alpha=Hyp[itr]).fit(train_mat, train_y_true)\n",
    "    f1 , acc = getClassifierEff (valid_mat,valid_y_true,naive_clf)\n",
    "    IMDB_valid_f1.append(f1)\n",
    "    IMDB_valid_acc.append(acc)\n",
    "   # print('IMDB_valid_f1',IMDB_valid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for hyper parameter alpha = 0.01 we get max F1 score\n"
     ]
    }
   ],
   "source": [
    "optim_alpha = Hyp[np.argmax(IMDB_valid_f1)]\n",
    "print('for hyper parameter alpha =',Hyp[np.argmax(IMDB_valid_f1)],'we get max F1 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB_train_f1 0.8598\n",
      "IMDB_test_f1 0.81252\n",
      "IMDB_valid_f1 0.8288\n"
     ]
    }
   ],
   "source": [
    "naive_clf = MultinomialNB( alpha=optim_alpha ).fit(train_mat, train_y_true)\n",
    "\n",
    "train_f1 , train_acc = getClassifierEff (train_mat,train_y_true,naive_clf)\n",
    "test_f1 , test_acc = getClassifierEff (test_mat,test_y_true,naive_clf)\n",
    "valid_f1 , valid_acc = getClassifierEff (valid_mat,valid_y_true,naive_clf)\n",
    "\n",
    "print('IMDB_train_f1',train_f1)\n",
    "print('IMDB_test_f1',test_f1)\n",
    "print('IMDB_valid_f1',valid_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0301ecf396e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mIMDB_valid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnaive_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_mat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetClassifierEff\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_mat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_y_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnaive_clf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mIMDB_valid_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\machine learning\\python 3.5.2\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m--> 185\u001b[1;33m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\machine learning\\python 3.5.2\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;31m# boost the variance by epsilon, a small fraction of the standard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;31m# deviation of the largest dimension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-9\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_refit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\machine learning\\python 3.5.2\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m   3192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3193\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[1;32m-> 3194\u001b[1;33m                          **kwargs)\n\u001b[0m",
      "\u001b[1;32md:\\machine learning\\python 3.5.2\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;31m# not a scalar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IMDB_valid_f1 = []\n",
    "IMDB_valid_acc = []\n",
    "\n",
    "naive_clf = GaussianNB().fit(train_mat.toarray(), train_y_true)\n",
    "f1 , acc = getClassifierEff (valid_mat.toarray(),valid_y_true,naive_clf)\n",
    "IMDB_valid_f1 = f1\n",
    "IMDB_valid_acc = acc\n",
    "\n",
    "train_f1 , train_acc = getClassifierEff (train_mat.toarray(),train_y_true,naive_clf)\n",
    "test_f1 , test_acc = getClassifierEff (test_mat.toarray(),test_y_true,naive_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.tree.DecisionTreeClassifier(criterion=’gini’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = ['gini','entropy'] #criterion \n",
    "split = ['best','random'] #splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB_valid_f1 0.6971 when we use criterion gini and splitter best\n",
      "IMDB_valid_f1 0.7033 when we use criterion gini and splitter random\n",
      "IMDB_valid_f1 0.6972 when we use criterion entropy and splitter best\n",
      "IMDB_valid_f1 0.7079000000000001 when we use criterion entropy and splitter random\n"
     ]
    }
   ],
   "source": [
    "IMDB_valid_f1 = []\n",
    "IMDB_valid_acc = []\n",
    "for itr1 in range(len(crit)):\n",
    "    for itr2 in range(len(split)):\n",
    "        tree_clf = tree.DecisionTreeClassifier(criterion = crit[itr1], splitter = split[itr2]).fit(train_mat, train_y_true)\n",
    "        f1,acc = getClassifierEff (valid_mat,valid_y_true,tree_clf)\n",
    "        IMDB_valid_f1.append(f1)\n",
    "        IMDB_valid_acc.append(acc)\n",
    "        \n",
    "        print('IMDB_valid_f1',f1,'when we use criterion',crit[itr1],'and splitter',split[itr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB_train_f1 1.0\n",
      "IMDB_test_f1 0.69984\n"
     ]
    }
   ],
   "source": [
    "tree_clf = tree.DecisionTreeClassifier(criterion = 'entropy', splitter = 'best').fit(train_mat, train_y_true)\n",
    "IMDB_train_f1,IMDB_train_acc = getClassifierEff (train_mat,train_y_true,tree_clf)\n",
    "IMDB_test_f1,IMDB_test_acc = getClassifierEff (test_mat,test_y_true,tree_clf)\n",
    "\n",
    "print('IMDB_train_f1',IMDB_train_f1)\n",
    "print('IMDB_test_f1',IMDB_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.svm.LinearSVC(penalty=’l2’, loss=’squared_hinge’, dual=True, tol=0.0001, C=1.0, multi_class=’ovr’, fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_clf = LinearSVC().fit(train_mat, train_y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for combination of penalty='l2' , loss='hinge',dual=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = ['l2']\n",
    "los = ['hinge'] # gives error for hinge\n",
    "dul = [True] # gives error for dual = true. \n",
    "tolerance = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1,1]\n",
    "C_param = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB_valid_f1 0.8427 when we use penalty l2 loss hinge dual True\n"
     ]
    }
   ],
   "source": [
    "IMDB_valid_f1 = []\n",
    "IMDB_valid_acc = []\n",
    "for itr1 in range(len(pen)):\n",
    "\n",
    "    linear_clf = LinearSVC(penalty='l2' , loss='hinge', dual=True).fit(train_mat, train_y_true)\n",
    "    f1 , acc = getClassifierEff (valid_mat,valid_y_true,linear_clf)\n",
    "    IMDB_valid_f1.append(f1)\n",
    "    IMDB_valid_acc.append(acc)\n",
    "            \n",
    "    print('IMDB_valid_f1',f1,'when we use penalty',pen[itr1],'loss',los[itr1],'dual',dul[itr1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-10 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-10 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-10 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-10 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-10 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-10 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-10 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-10 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-10 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-10 C 0.1\n",
      "IMDB_valid_f1 0.8486 when we use penalty l2 tolerence 1e-10 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-09 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-09 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-09 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-09 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-09 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-09 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-09 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-09 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-09 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-09 C 0.1\n",
      "IMDB_valid_f1 0.8486 when we use penalty l2 tolerence 1e-09 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-08 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-08 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-08 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-08 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-08 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-08 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-08 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-08 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-08 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-08 C 0.1\n",
      "IMDB_valid_f1 0.8486 when we use penalty l2 tolerence 1e-08 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-07 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-07 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-07 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-07 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-07 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-07 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-07 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-07 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-07 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-07 C 0.1\n",
      "IMDB_valid_f1 0.8486 when we use penalty l2 tolerence 1e-07 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-06 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-06 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-06 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-06 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-06 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-06 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-06 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-06 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-06 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-06 C 0.1\n",
      "IMDB_valid_f1 0.8486 when we use penalty l2 tolerence 1e-06 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-05 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-05 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-05 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-05 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-05 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-05 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-05 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-05 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-05 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-05 C 0.1\n",
      "IMDB_valid_f1 0.8486 when we use penalty l2 tolerence 1e-05 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.0001 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 0.0001 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 0.0001 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 0.0001 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 0.0001 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 0.0001 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 0.0001 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 0.0001 C 0.001\n",
      "IMDB_valid_f1 0.8779 when we use penalty l2 tolerence 0.0001 C 0.01\n",
      "IMDB_valid_f1 0.8611000000000001 when we use penalty l2 tolerence 0.0001 C 0.1\n",
      "IMDB_valid_f1 0.849 when we use penalty l2 tolerence 0.0001 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.001 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 0.001 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 0.001 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 0.001 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 0.001 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 0.001 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 0.001 C 0.0001\n",
      "IMDB_valid_f1 0.8727 when we use penalty l2 tolerence 0.001 C 0.001\n",
      "IMDB_valid_f1 0.8781 when we use penalty l2 tolerence 0.001 C 0.01\n",
      "IMDB_valid_f1 0.8613 when we use penalty l2 tolerence 0.001 C 0.1\n",
      "IMDB_valid_f1 0.8508000000000001 when we use penalty l2 tolerence 0.001 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.01 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 0.01 C 1e-09\n",
      "IMDB_valid_f1 0.5177 when we use penalty l2 tolerence 0.01 C 1e-08\n",
      "IMDB_valid_f1 0.5846 when we use penalty l2 tolerence 0.01 C 1e-07\n",
      "IMDB_valid_f1 0.6622 when we use penalty l2 tolerence 0.01 C 1e-06\n",
      "IMDB_valid_f1 0.7359 when we use penalty l2 tolerence 0.01 C 1e-05\n",
      "IMDB_valid_f1 0.8304000000000001 when we use penalty l2 tolerence 0.01 C 0.0001\n",
      "IMDB_valid_f1 0.8725 when we use penalty l2 tolerence 0.01 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 0.01 C 0.01\n",
      "IMDB_valid_f1 0.8637 when we use penalty l2 tolerence 0.01 C 0.1\n",
      "IMDB_valid_f1 0.8537 when we use penalty l2 tolerence 0.01 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.1 C 1e-10\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.1 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 0.1 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 0.1 C 1e-07\n",
      "IMDB_valid_f1 0.6601 when we use penalty l2 tolerence 0.1 C 1e-06\n",
      "IMDB_valid_f1 0.7359 when we use penalty l2 tolerence 0.1 C 1e-05\n",
      "IMDB_valid_f1 0.8311 when we use penalty l2 tolerence 0.1 C 0.0001\n",
      "IMDB_valid_f1 0.874 when we use penalty l2 tolerence 0.1 C 0.001\n",
      "IMDB_valid_f1 0.8769999999999999 when we use penalty l2 tolerence 0.1 C 0.01\n",
      "IMDB_valid_f1 0.8721 when we use penalty l2 tolerence 0.1 C 0.1\n",
      "IMDB_valid_f1 0.8641 when we use penalty l2 tolerence 0.1 C 1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1 C 1e-10\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1 C 1e-09\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1 C 1e-07\n",
      "IMDB_valid_f1 0.6601 when we use penalty l2 tolerence 1 C 1e-06\n",
      "IMDB_valid_f1 0.7359 when we use penalty l2 tolerence 1 C 1e-05\n",
      "IMDB_valid_f1 0.8289 when we use penalty l2 tolerence 1 C 0.0001\n",
      "IMDB_valid_f1 0.8636 when we use penalty l2 tolerence 1 C 0.001\n",
      "IMDB_valid_f1 0.8652 when we use penalty l2 tolerence 1 C 0.01\n",
      "IMDB_valid_f1 0.8631 when we use penalty l2 tolerence 1 C 0.1\n",
      "IMDB_valid_f1 0.8646999999999999 when we use penalty l2 tolerence 1 C 1\n"
     ]
    }
   ],
   "source": [
    "IMDB_valid_f1 = []\n",
    "IMDB_valid_acc = []\n",
    "for itr1 in range(len(pen)):\n",
    "    for itr2 in range(len(tolerance)):\n",
    "        for itr3 in range(len(C_param)):\n",
    "            linear_clf = LinearSVC(penalty=pen[itr1],tol=tolerance[itr2],C=C_param[itr3],dual=False).fit(train_mat, train_y_true)\n",
    "            f1 , acc = getClassifierEff (valid_mat,valid_y_true,linear_clf)\n",
    "            IMDB_valid_f1.append(f1)\n",
    "            IMDB_valid_acc.append(acc)\n",
    "            \n",
    "            print('IMDB_valid_f1',f1,'when we use penalty',pen[itr1],'tolerence',tolerance[itr2],'C',C_param[itr3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB_train_f1 0.9415333333333333\n",
      "IMDB_test_f1 0.87272\n",
      "IMDB_valid_f1 0.8796999999999999\n"
     ]
    }
   ],
   "source": [
    "linear_clf = LinearSVC(penalty='l2',tol=0.01,C=0.01,loss='hinge',dual=True).fit(train_mat, train_y_true)\n",
    "IMDB_train_f1,IMDB_train_acc = getClassifierEff (train_mat,train_y_true,linear_clf)\n",
    "IMDB_test_f1,IMDB_test_acc = getClassifierEff (test_mat,test_y_true,linear_clf)\n",
    "IMDB_valid_f1,IMDB_valid_acc = getClassifierEff (valid_mat,valid_y_true,linear_clf)\n",
    "print('IMDB_train_f1',IMDB_train_f1)\n",
    "print('IMDB_test_f1',IMDB_test_f1)\n",
    "print('IMDB_valid_f1',IMDB_valid_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for combination of penalty='l1','l2' , loss='squred_hinge',dual=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = ['l1','l2']\n",
    "los = ['squared_hinge'] # gives error for hinge\n",
    "dul = [False] # gives error for dual = true. \n",
    "tolerance = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "C_param = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-10 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-10 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-10 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-10 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-10 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-10 C 1e-05\n",
      "IMDB_valid_f1 0.5256 when we use penalty l1 tolerence 1e-10 C 0.0001\n",
      "IMDB_valid_f1 0.7292999999999998 when we use penalty l1 tolerence 1e-10 C 0.001\n",
      "IMDB_valid_f1 0.8461 when we use penalty l1 tolerence 1e-10 C 0.01\n",
      "IMDB_valid_f1 0.8694 when we use penalty l1 tolerence 1e-10 C 0.1\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-09 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-09 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-09 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-09 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-09 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-09 C 1e-05\n",
      "IMDB_valid_f1 0.5256 when we use penalty l1 tolerence 1e-09 C 0.0001\n",
      "IMDB_valid_f1 0.7302999999999998 when we use penalty l1 tolerence 1e-09 C 0.001\n",
      "IMDB_valid_f1 0.8462 when we use penalty l1 tolerence 1e-09 C 0.01\n",
      "IMDB_valid_f1 0.8695 when we use penalty l1 tolerence 1e-09 C 0.1\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-08 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-08 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-08 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-08 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-08 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-08 C 1e-05\n",
      "IMDB_valid_f1 0.5256 when we use penalty l1 tolerence 1e-08 C 0.0001\n",
      "IMDB_valid_f1 0.7302999999999998 when we use penalty l1 tolerence 1e-08 C 0.001\n",
      "IMDB_valid_f1 0.8462 when we use penalty l1 tolerence 1e-08 C 0.01\n",
      "IMDB_valid_f1 0.8695999999999999 when we use penalty l1 tolerence 1e-08 C 0.1\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-07 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-07 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-07 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-07 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-07 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-07 C 1e-05\n",
      "IMDB_valid_f1 0.5256 when we use penalty l1 tolerence 1e-07 C 0.0001\n",
      "IMDB_valid_f1 0.7302999999999998 when we use penalty l1 tolerence 1e-07 C 0.001\n",
      "IMDB_valid_f1 0.8462 when we use penalty l1 tolerence 1e-07 C 0.01\n",
      "IMDB_valid_f1 0.8695999999999999 when we use penalty l1 tolerence 1e-07 C 0.1\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-06 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-06 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-06 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-06 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-06 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-06 C 1e-05\n",
      "IMDB_valid_f1 0.5256 when we use penalty l1 tolerence 1e-06 C 0.0001\n",
      "IMDB_valid_f1 0.7302999999999998 when we use penalty l1 tolerence 1e-06 C 0.001\n",
      "IMDB_valid_f1 0.8462 when we use penalty l1 tolerence 1e-06 C 0.01\n",
      "IMDB_valid_f1 0.8695999999999999 when we use penalty l1 tolerence 1e-06 C 0.1\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-05 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-05 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-05 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-05 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-05 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 1e-05 C 1e-05\n",
      "IMDB_valid_f1 0.5256 when we use penalty l1 tolerence 1e-05 C 0.0001\n",
      "IMDB_valid_f1 0.7302999999999998 when we use penalty l1 tolerence 1e-05 C 0.001\n",
      "IMDB_valid_f1 0.8462 when we use penalty l1 tolerence 1e-05 C 0.01\n",
      "IMDB_valid_f1 0.8695999999999999 when we use penalty l1 tolerence 1e-05 C 0.1\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.0001 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.0001 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.0001 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.0001 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.0001 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.0001 C 1e-05\n",
      "IMDB_valid_f1 0.5256 when we use penalty l1 tolerence 0.0001 C 0.0001\n",
      "IMDB_valid_f1 0.7302999999999998 when we use penalty l1 tolerence 0.0001 C 0.001\n",
      "IMDB_valid_f1 0.8462 when we use penalty l1 tolerence 0.0001 C 0.01\n",
      "IMDB_valid_f1 0.8695999999999999 when we use penalty l1 tolerence 0.0001 C 0.1\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.001 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.001 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.001 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.001 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.001 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.001 C 1e-05\n",
      "IMDB_valid_f1 0.5256 when we use penalty l1 tolerence 0.001 C 0.0001\n",
      "IMDB_valid_f1 0.7302 when we use penalty l1 tolerence 0.001 C 0.001\n",
      "IMDB_valid_f1 0.8462 when we use penalty l1 tolerence 0.001 C 0.01\n",
      "IMDB_valid_f1 0.8695999999999999 when we use penalty l1 tolerence 0.001 C 0.1\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.01 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.01 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.01 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.01 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.01 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.01 C 1e-05\n",
      "IMDB_valid_f1 0.5256 when we use penalty l1 tolerence 0.01 C 0.0001\n",
      "IMDB_valid_f1 0.7308 when we use penalty l1 tolerence 0.01 C 0.001\n",
      "IMDB_valid_f1 0.8463 when we use penalty l1 tolerence 0.01 C 0.01\n",
      "IMDB_valid_f1 0.8701 when we use penalty l1 tolerence 0.01 C 0.1\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.1 C 1e-10\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.1 C 1e-09\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.1 C 1e-08\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.1 C 1e-07\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.1 C 1e-06\n",
      "IMDB_valid_f1 0.5 when we use penalty l1 tolerence 0.1 C 1e-05\n",
      "IMDB_valid_f1 0.5191 when we use penalty l1 tolerence 0.1 C 0.0001\n",
      "IMDB_valid_f1 0.7317999999999999 when we use penalty l1 tolerence 0.1 C 0.001\n",
      "IMDB_valid_f1 0.8447999999999999 when we use penalty l1 tolerence 0.1 C 0.01\n",
      "IMDB_valid_f1 0.8724 when we use penalty l1 tolerence 0.1 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-10 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-10 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-10 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-10 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-10 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-10 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-10 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-10 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-10 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-10 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-09 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-09 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-09 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-09 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-09 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-09 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-09 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-09 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-09 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-09 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-08 C 1e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-08 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-08 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-08 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-08 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-08 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-08 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-08 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-08 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-08 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-07 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-07 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-07 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-07 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-07 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-07 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-07 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-07 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-07 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-07 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-06 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-06 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-06 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-06 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-06 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-06 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-06 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-06 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-06 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-06 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 1e-05 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 1e-05 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 1e-05 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 1e-05 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 1e-05 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 1e-05 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 1e-05 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 1e-05 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 1e-05 C 0.01\n",
      "IMDB_valid_f1 0.8606 when we use penalty l2 tolerence 1e-05 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.0001 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 0.0001 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 0.0001 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 0.0001 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 0.0001 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 0.0001 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 0.0001 C 0.0001\n",
      "IMDB_valid_f1 0.8727999999999999 when we use penalty l2 tolerence 0.0001 C 0.001\n",
      "IMDB_valid_f1 0.8779 when we use penalty l2 tolerence 0.0001 C 0.01\n",
      "IMDB_valid_f1 0.8611000000000001 when we use penalty l2 tolerence 0.0001 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.001 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 0.001 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 0.001 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 0.001 C 1e-07\n",
      "IMDB_valid_f1 0.6623 when we use penalty l2 tolerence 0.001 C 1e-06\n",
      "IMDB_valid_f1 0.736 when we use penalty l2 tolerence 0.001 C 1e-05\n",
      "IMDB_valid_f1 0.8303 when we use penalty l2 tolerence 0.001 C 0.0001\n",
      "IMDB_valid_f1 0.8727 when we use penalty l2 tolerence 0.001 C 0.001\n",
      "IMDB_valid_f1 0.8781 when we use penalty l2 tolerence 0.001 C 0.01\n",
      "IMDB_valid_f1 0.8613 when we use penalty l2 tolerence 0.001 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.01 C 1e-10\n",
      "IMDB_valid_f1 0.5081 when we use penalty l2 tolerence 0.01 C 1e-09\n",
      "IMDB_valid_f1 0.5177 when we use penalty l2 tolerence 0.01 C 1e-08\n",
      "IMDB_valid_f1 0.5846 when we use penalty l2 tolerence 0.01 C 1e-07\n",
      "IMDB_valid_f1 0.6622 when we use penalty l2 tolerence 0.01 C 1e-06\n",
      "IMDB_valid_f1 0.7359 when we use penalty l2 tolerence 0.01 C 1e-05\n",
      "IMDB_valid_f1 0.8304000000000001 when we use penalty l2 tolerence 0.01 C 0.0001\n",
      "IMDB_valid_f1 0.8725 when we use penalty l2 tolerence 0.01 C 0.001\n",
      "IMDB_valid_f1 0.8778 when we use penalty l2 tolerence 0.01 C 0.01\n",
      "IMDB_valid_f1 0.8637 when we use penalty l2 tolerence 0.01 C 0.1\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.1 C 1e-10\n",
      "IMDB_valid_f1 0.5076 when we use penalty l2 tolerence 0.1 C 1e-09\n",
      "IMDB_valid_f1 0.518 when we use penalty l2 tolerence 0.1 C 1e-08\n",
      "IMDB_valid_f1 0.5849 when we use penalty l2 tolerence 0.1 C 1e-07\n",
      "IMDB_valid_f1 0.6601 when we use penalty l2 tolerence 0.1 C 1e-06\n",
      "IMDB_valid_f1 0.7359 when we use penalty l2 tolerence 0.1 C 1e-05\n",
      "IMDB_valid_f1 0.8311 when we use penalty l2 tolerence 0.1 C 0.0001\n",
      "IMDB_valid_f1 0.874 when we use penalty l2 tolerence 0.1 C 0.001\n",
      "IMDB_valid_f1 0.8769999999999999 when we use penalty l2 tolerence 0.1 C 0.01\n",
      "IMDB_valid_f1 0.8721 when we use penalty l2 tolerence 0.1 C 0.1\n"
     ]
    }
   ],
   "source": [
    "IMDB_valid_f1 = []\n",
    "IMDB_valid_acc = []\n",
    "for itr1 in range(len(pen)):\n",
    "    for itr2 in range(len(tolerance)):\n",
    "        for itr3 in range(len(C_param)):\n",
    "            linear_clf = LinearSVC(penalty=pen[itr1],tol=tolerance[itr2],C=C_param[itr3],dual=False).fit(train_mat, train_y_true)\n",
    "            f1 , acc = getClassifierEff (valid_mat,valid_y_true,linear_clf)\n",
    "            IMDB_valid_f1.append(f1)\n",
    "            IMDB_valid_acc.append(acc)\n",
    "            \n",
    "            print('IMDB_valid_f1',f1,'when we use penalty',pen[itr1],'tolerence',tolerance[itr2],'C',C_param[itr3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB_train_f1 0.9715333333333334\n",
      "IMDB_test_f1 0.86928\n",
      "IMDB_valid_f1 0.8778\n"
     ]
    }
   ],
   "source": [
    "linear_clf = LinearSVC(penalty='l2',tol=0.01,C=0.01,loss='squared_hinge',dual=False).fit(train_mat, train_y_true)\n",
    "IMDB_train_f1,IMDB_train_acc = getClassifierEff (train_mat,train_y_true,linear_clf)\n",
    "IMDB_test_f1,IMDB_test_acc = getClassifierEff (test_mat,test_y_true,linear_clf)\n",
    "IMDB_valid_f1,IMDB_valid_acc = getClassifierEff (valid_mat,valid_y_true,linear_clf)\n",
    "print('IMDB_train_f1',IMDB_train_f1)\n",
    "print('IMDB_test_f1',IMDB_test_f1)\n",
    "print('IMDB_valid_f1',IMDB_valid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
